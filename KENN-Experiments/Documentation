WHAT HAS DO BE DONE:
- Added datasets Flickr, Yelp, AmazonProducts, Reddit2
- Re-implemented GraphSAINT, ClusterGCN, GraphSAGE
- Re-implemented Sampling Pipeline: Each model has its own train sampling procedure now
- Enabled Edge Weights and Edge weight normalization "conf - normalize_edges"
- Linear and Logistic Regression Pipeline
- ToInductive() only removes edges between train, valid and test now, not nodes! Nodes are always referenced with masks
- GAT (Graph Attention Network) added as baseline
- Random dropping of edges in the training set (by percentage) to check how helpful KENN is when links are missing
- Test with different sets of knowledge and mask links: knowledge can be selected based on stats for clause compliance and
absolute quantity of class
- Cleaning the code: more funcitonality in model class

TODO
- Set relations to trainable? / set binary preactivations to trainable and node classifications to fixed values?
- More info on resources: Memory consumption etc.

# How to categorize experiments?

(1) Experiments where full-batch traininig is feasible
--- Try out

(2) Experiments where batching is needed (CUDA OOM)
---

1. Hyperparameter optimization
- https://docs.wandb.ai/guides/sweeps/initialize-sweeps
- wandb sweep:
- Parameters to be optimized:
-- (1) Determine parameters for Base NN
-------

